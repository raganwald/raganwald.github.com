What if ChatGPT tells us more about what it is to be human, than it does about the state of AI today?

The first “natural language” program I every played with was the famous ELIZA, a fixed algorithm that pretended to be a Freudean therapist.

https://en.wikipedia.org/wiki/ELIZA

By the time I reached college, I had heard all about “The Turing Test.” To recap, the Turing Test consists of a human interrogating two subjects, a computer and another human, in a setup that doesn’t allow the interrogator to know which of their subjects is a human, and which is a computer.

In those days, a qualifying setup might have had the interrogator communicating with both subjects by teletype. Today, a Turing Test might be communicating with people over Twitter, and trying to figure out which are human and which are bots.

The salient point is that the Turing Test depends upon the behaviour of all THREE participants: The behaviour of the two subjects is presumed to be the point of the test, but for the computer to “win,” it doesn’t have to be intelligent, it only has to behave in a way that fools the interrogator.

So while the test is positioned as a test of computer behaviour, it’s also a test of the ability of humans to recognize machine behaviour. Which brings us to ChatGPT and other modern advances in AI.

They do not have to be intelligent, they only have to be intelligent enough to fool humans. And it could very well be that they can reach that standard in practice, given certain limited scopes, because humans are actually quite vulnerable to being fooled.

We aren’t nearly as smart as we think we are, and we get conned all the time. We buy a car that will have “Full Self-Driving” later this year… ten years ago and we’re still waiting.

We believe that a pedophile ring is using a pizza parlour as a cover like some kind of Spy-Fy plot device. Or that there’s this one vegetable you can eat that plastic surgeons don’t want you to know about. Or… But the point is now obvious: Humans are quite fallible can can easily be fooled.

Which brings us to a word that is very important to know in sales and marketing: VERISIMILITUDE, which is defined as: “Something that has the appearance of being true or real.”

Note that verisimilitude is not the property of being true. It is the property of appealing to whatever biases humans have for deciding what seems likely to be true, even if we are not experts in the field.

Verisimilitude is easy to hack. It is why politicians love to campaign on simple answers to complex problems: Simple answers have verisimilitude for people unfamiliar with complex domains. Complex answers do not.

And therein lies the limitation of the Turing Test: It is not a test of whether AI is intelligent (whatever that means), it is also a test of whether AI can have verisimilitude. 

And likewise, using ChatGPT It is a test of whether AI, trained on a large corpus of text that humans have vetted as appearing to be true, can produce more text that also appears to be true.

